% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api.R
\name{plot_fair_average}
\alias{plot_fair_average}
\title{Plot fair-average diagnostics using base R}
\usage{
plot_fair_average(
  x,
  diagnostics = NULL,
  facet = NULL,
  metric = c("FairM", "FairZ"),
  plot_type = c("difference", "scatter"),
  top_n = 40,
  draw = TRUE,
  ...
)
}
\arguments{
\item{x}{Output from \code{\link[=fit_mfrm]{fit_mfrm()}} or \code{\link[=fair_average_table]{fair_average_table()}}.}

\item{diagnostics}{Optional output from \code{\link[=diagnose_mfrm]{diagnose_mfrm()}} when \code{x} is \code{mfrm_fit}.}

\item{facet}{Optional facet name for level-wise lollipop plots.}

\item{metric}{Fair-average metric (\code{"FairM"} or \code{"FairZ"}).}

\item{plot_type}{\code{"difference"} or \code{"scatter"}.}

\item{top_n}{Maximum levels shown for \code{"difference"} plot.}

\item{draw}{If \code{TRUE}, draw with base graphics.}

\item{...}{Additional arguments passed to \code{\link[=fair_average_table]{fair_average_table()}} when \code{x} is \code{mfrm_fit}.}
}
\value{
A plotting-data object of class \code{mfrm_plot_data}.
}
\description{
Plot fair-average diagnostics using base R
}
\details{
Fair-average plots compare observed scoring tendency against model-based
fair metrics.
}
\section{Plot types}{

\describe{
\item{\code{"difference"} (default)}{Lollipop chart showing the gap between
observed and fair-average score for each element.  X-axis:
Observed - Fair metric.  Y-axis: element labels.  Points colored
teal (lenient, gap >= 0) or orange (severe, gap < 0).  Ordered by
absolute gap.}
\item{\code{"scatter"}}{Scatter plot of fair metric (x) vs observed average
(y) with an identity line.  Points colored by facet.  Useful for
checking overall alignment between observed and model-adjusted
scores.}
}
}

\section{Interpreting output}{

Difference plot: ranked element-level gaps (\code{Observed - Fair}), useful
for triage of potentially lenient/severe levels.

Scatter plot: global agreement pattern relative to the identity line.

Larger absolute gaps suggest stronger divergence between observed and
model-adjusted scoring.
}

\section{Typical workflow}{

\enumerate{
\item Start with \code{plot_type = "difference"} to find largest discrepancies.
\item Use \code{plot_type = "scatter"} to check overall alignment pattern.
\item Follow up with facet-level diagnostics for flagged levels.
}
}

\examples{
toy <- expand.grid(
  Person = paste0("P", 1:4),
  Rater = paste0("R", 1:2),
  Criterion = c("Content", "Organization", "Language"),
  stringsAsFactors = FALSE
)
toy$Score <- (
  as.integer(factor(toy$Person)) +
  2 * as.integer(factor(toy$Rater)) +
  as.integer(factor(toy$Criterion))
) \%\% 3
fit <- fit_mfrm(toy, "Person", c("Rater", "Criterion"), "Score", method = "JML", maxit = 25)
p <- plot_fair_average(fit, metric = "FairM", draw = FALSE)
if (interactive()) {
  plot_fair_average(fit, metric = "FairM", plot_type = "difference")
}
}
\seealso{
\code{\link[=fair_average_table]{fair_average_table()}}, \code{\link[=plot_unexpected]{plot_unexpected()}}, \code{\link[=plot_displacement]{plot_displacement()}}, \code{\link[=plot_qc_dashboard]{plot_qc_dashboard()}}
}
